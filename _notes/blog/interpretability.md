---
layout: notes_without_title
section-type: notes
title: interpretability
category: blog
---


# interpretability
**chandan singh** 
*last updated jul 20, 2018*

---

Modern machine learning models, particulary deep neural networks, are difficult to understand and explain. This has consequences when these networks are used to make critical decisions. Thus it is important to develop methods that can interpret these highly complex models.