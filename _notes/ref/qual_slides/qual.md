---
title: Chandan's slides
separator: '---'
verticalSeparator: '--'
theme: black
highlightTheme: ir-black
typora-copy-images-to: ./assets
---
<h1> towards interpretable machine learning for neuroscience </h1>

<h3> chandan singh </h3> 

*advised by bin yu*

## collaborators

- prof. bin yu
  - jamie murdoch
  - karl kumbier
  - reza abbasi-asl
- prof. jack gallant
  - michael eickenberg
  - michael oliver



## machine learning is powerful

- strong predictive performance
- often perceived as black-box

## interpretable ml framework

with *jamie murdoch, karl kumbier, reza abbasi-asl, & bin yu*

- variety of different places where interpretability comes in

## big-data neuroscience

- lots of challenges with understanding the brain
- needs interpretability

## intersection of different approaches

- theory
- data-driven experiments
- fine-tuned experiments



## overview

1. [interpreting dnns](#/1)
2. [v4 proj](#/2)

# explaining dnn predictions to humans

*with jamie murdoch & bin yu*

## problem

explain a **single prediction** by a dnn in terms of the **input**



## previous work

- LRP
- LIME

## decomposition

- CD (for LSTMS)

## extending CD

- work with CNNs

## hierarchical interpretation

- ACD

## qualitative results



## quantitative results



## future work

- building similar trees at the dataset-level



# v4 project

*with michael eickenberg, michael oliver, reza abbasi-asl, jack gallant, & bin yu*

## background

## previous work: deeptune

- deeptune analysis

## experiment

## eda

## analysis

## goal



# future work



# appendix

1. [interpreting dnns](#/1)
2. [v4 proj](#/2)
3. [v1 proj](#/3)





<style>

.reveal h1,
.reveal h2,
.reveal h3,
.reveal h4,
.reveal h5,
.reveal h6 {
​	text-transform: lowercase;
}

.reveal section img { 
​	background:none; 
​	border:none; 
​	box-shadow:none; 
}

	filter: invert(1); 
}

iframe {
​    filter: invert(1);
}


body {
  background: #000;
  background-color: #000; 
}



</style>